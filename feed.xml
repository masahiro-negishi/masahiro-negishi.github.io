<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.2">Jekyll</generator><link href="https://masahiro-negishi.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://masahiro-negishi.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2023-11-20T13:03:21+00:00</updated><id>https://masahiro-negishi.github.io/feed.xml</id><title type="html">Masahiro Negishi</title><subtitle>A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. </subtitle><entry><title type="html">Responsible AI</title><link href="https://masahiro-negishi.github.io/blog/2023/workshop-responsible-ai/" rel="alternate" type="text/html" title="Responsible AI"/><published>2023-11-20T00:00:00+00:00</published><updated>2023-11-20T00:00:00+00:00</updated><id>https://masahiro-negishi.github.io/blog/2023/workshop-responsible-ai</id><content type="html" xml:base="https://masahiro-negishi.github.io/blog/2023/workshop-responsible-ai/"><![CDATA[<p>Note: This post is under construction.</p> <p>This post is about what I learned in an educational workshop on Responsible AI for Peace and Security, held in Malmö, Sweden on 16 and 17 November, 2023.</p> <h2 id="1-introduction">1. Introduction</h2> <p>With the recent widespread adoption of AI technologies, lively debates have emerged regarding the associated risks. These discussions span a spectrum from concerns about AI replacing jobs to the potential threat of autonomous robots causing harm to humans. However, these debates often remain superficial, particularly among the general public, as terms like “AI” or “Risk” carry vague meanings. Seeking a deeper understanding of the current landscape of AI risks and exploring effective approaches to address them, I participated in an enlightening educational workshop on Responsible AI for Peace and Security in Malmö, Sweden, held on November 16 and 17, 2023. This post aims to distill the insights gained during the two-day workshop, hoping to contribute to a clearer perspective on the challenges posed by AI risks.</p> <h2 id="2-ai-risks-on-peace-and-security">2. AI risks on peace and security</h2> <h2 id="3-how-to-mitigate-the-ai-risks">3. How to mitigate the AI risks</h2> <h2 id="4-responsible-innovation-of-ai">4. Responsible innovation of AI</h2> <h2 id="5-possible-scenarios">5. Possible scenarios</h2> <h2 id="6-takeaways">6. Takeaways</h2>]]></content><author><name></name></author><category term="AI"/><summary type="html"><![CDATA[What are AI risks and how to mitigate them]]></summary></entry><entry><title type="html">EM algorithm</title><link href="https://masahiro-negishi.github.io/blog/2023/em-algorithm/" rel="alternate" type="text/html" title="EM algorithm"/><published>2023-10-16T00:00:00+00:00</published><updated>2023-10-16T00:00:00+00:00</updated><id>https://masahiro-negishi.github.io/blog/2023/em-algorithm</id><content type="html" xml:base="https://masahiro-negishi.github.io/blog/2023/em-algorithm/"><![CDATA[<h2 id="table-of-contents">Table of Contents</h2> <ul> <li><a href="#1-problem-setting">Problem setting</a></li> <li><a href="#2-background">Background</a></li> <li><a href="#3-algorithm">Algorithm</a></li> <li><a href="#4-reference">Reference</a></li> </ul> <h2 id="1-problem-setting">1. Problem setting</h2> <p>Assume there are latent variables \(z\), which cannot be observed. The goal is to maximize likelihood \(\log p _ {\theta} (x)\), where \(x\) is observed variables. More specifically, given the training set $X$, the objective is to maximize likelihood \(\log p _ {\theta} (X)\). We assume two things to make the problem solvable with EM algorithm:</p> <ul> <li>\(p _ {\theta} (x, z)\) is tractable (For M step)</li> <li>\(p _ {\theta} (z \vert x)\) is tractable (For E step)</li> </ul> <h2 id="2-background">2. Background</h2> <p>You cannot directly maxmize \(\log p _ {\theta} (x)\), thus we consider evidence lower bound (ELBO) as follows:</p> \[\begin{aligned} \log p _ {\theta} (x) &amp;= \log p _ {\theta} (x) \int q(z)dz \\ &amp;= \int q(z) \log \frac{q(z) p _ {\theta} (x, z)}{q(z) p _ {\theta} (z \vert x)}dz \\ &amp;= \int q(z) \log \frac{p _ {\theta} (x, z)}{q(z)}dz + \int q(z) \log \frac{q(z)}{p _ {\theta} (z \vert x)}dz \\ &amp;= \mathcal{L} (q, \theta; x) + D _ {KL} [q(z) \Vert p _ {\theta} (z \vert x)]. \end{aligned}\] <p>You can also derive that \(\mathcal{L} (q, \theta; x)\) is a lower bound of \(\log p _ {\theta} (x)\) by utilizing Jensen’s inequality:</p> \[\begin{aligned} \log p _ {\theta} (x) &amp;= \log \int p _ {\theta} (x, z) dz \\ &amp;= \log \int q(z) \frac{p _ {\theta} (x, z)}{q(z)} dz \\ &amp;\ge \int q(z) \log \frac{p _ {\theta} (x, z)}{q(z)} dz \\ &amp;= \mathcal{L} (q, \theta; x). \end{aligned}\] <h2 id="3-algorithm">3. Algorithm</h2> <p>EM algorithm iterates two steps to maximize \(\mathcal{L} (q, \theta; x) = \log p _ {\theta} (x) - D _ {KL} [q(z) \Vert p _ {\theta} (z \vert x)]\).</p> <h3 id="31-e-step">3.1. E step</h3> <p>E step maximizes \(\mathcal{L} (q, \theta _ t; x)\) in terms of \(q\). This corresponds to minimizing \(D _ {KL} [q(z) \Vert p _ {\theta _ t} (z \vert x)]\) in terms of \(q\). Thus, E step updates \(q(z)\) as follows:</p> \[q(z) = p _ {\theta _ t} (z \vert x)\] <h3 id="32-m-step">3.2. M step</h3> <p>M step maximizes \(\mathcal{L} (q, \theta; x)\) in terms of \(\theta\). Note that \(q(x)\) is set to \(p _ {\theta _ t} (z \vert x)\) in the last E step.</p> \[\begin{aligned} \theta _ {t+1} &amp;\mathrel{\vcenter{:}}= \underset{\theta}{\text{argmax}} \mathcal{L} (p _ {\theta _ t} (z \vert x), \theta; x) \\ &amp;= \underset{\theta}{\text{argmax}} \int p _ {\theta _ t} (z \vert x) \log \frac{p _ {\theta} (x, z)}{p _ {\theta _ t} (z \vert x)}dz \\ &amp;= \underset{\theta}{\text{argmax}} \int p _ {\theta _ t} (z \vert x) \log p _ {\theta} (x, z)dz \\ \end{aligned}\] <p>Note: \(\log p _ \theta (x)\) monotonically increases, thus \(\theta _ t\) will converge to a local optima.</p> <h2 id="4-reference">4. Reference</h2> <ul> <li>Summer seminar “Deep Generative Models” provided by <a href="https://weblab.t.u-tokyo.ac.jp/">Matsuo Lab</a></li> <li><a href="https://academ-aid.com/ml/em">A website provides a mathematical details</a></li> </ul>]]></content><author><name></name></author><category term="ML"/><category term="generative-model"/><summary type="html"><![CDATA[derivation of EM algorithm]]></summary></entry><entry><title type="html">Overview of Generative Models</title><link href="https://masahiro-negishi.github.io/blog/2023/generative-models/" rel="alternate" type="text/html" title="Overview of Generative Models"/><published>2023-10-16T00:00:00+00:00</published><updated>2023-10-16T00:00:00+00:00</updated><id>https://masahiro-negishi.github.io/blog/2023/generative-models</id><content type="html" xml:base="https://masahiro-negishi.github.io/blog/2023/generative-models/"><![CDATA[<h2 id="table-of-contents">Table of Contents</h2> <ul> <li><a href="#1-motivation">Motivation</a></li> <li><a href="#2-learning">Learning</a></li> <li><a href="#3-reference">Reference</a></li> </ul> <h2 id="1-motivation">1. Motivation</h2> <p>We assume that there is a true data distribution \(p_{data}(x)\), which is only accessible through \(\lbrace x_1, x_2, ..., x_N \rbrace\) that are sampled from \(p_{data}(x)\). The goal of generative models is to find an approximation of \(p_{data}(x)\):</p> \[p_{\theta}(x) \approx p_{data}(x).\] <p>A generative model is composed of its architecture and its parameter \(\theta\). The architecture reflects people’s thought on how \(p_{data}(x)\) looks like. Parameter \(\theta\) determines remaining things. There are many applications of generative models including:</p> <ul> <li>generation of new samples</li> <li>abnormal detection, outlier detection</li> <li>denoising, missing value completion</li> </ul> <h2 id="2-learning">2. Learning</h2> <p>As written in Section 1, the goal is to learn \(p_{\theta}(x)\) that approximates \(p_{data}(x)\). There are two issues to achieve this goal.</p> <ul> <li>Issue 1: \(p_{data}(x)\) is unknown</li> <li>Issue 2: It is unclear how to measure the “distance” between \(p_{data}(x)\) and \(p_{\theta}(x)\).</li> </ul> <p>The first issue can be solved by approximating \(p_{data}(x)\) with an empirical distribution \(\hat{p}_{data}^{N}(x) \mathrel{\vcenter{:}}= \frac{1}{N}\sum_{i=1}^{N}\delta(x-x_i)\). The second issue can be solved by introducing KL divergence \(D_{KL}[p(x) \Vert q(x)] \mathrel{\vcenter{:}}= \mathbb{E}_{p(x)}[\log\frac{p(x)}{q(x)}]\). As a result, the learning objective is to derive the following \(\hat{\theta}\):</p> \[\begin{aligned} \hat{\theta} &amp;\mathrel{\vcenter{:}}= \underset{\theta}{\text{argmin}} D_{KL}[\hat{p}_{data}^{N}(x) \Vert p_{\theta}(x)] \\ &amp;= \underset{\theta}{\text{argmin}} \mathbb{E}_{\hat{p}_{data}^{N}(x)}[\log \hat{p}_{data}^{N}(x)] - \mathbb{E}_{\hat{p}_{data}^{N}(x)}[\log p_{\theta}(x)] \\ &amp;= \underset{\theta}{\text{argmax}} \mathbb{E}_{\hat{p}_{data}^{N}(x)}[\log p_{\theta}(x)] \\ &amp;= \underset{\theta}{\text{argmax}} \frac{1}{N} \sum_{i=1}^{N}\log p_{\theta}(x_i) \\ \bigl( &amp;= \underset{\theta}{\text{argmax}} \prod_{i=1}^{N}p_{\theta}(x_i) \bigr) \\ \end{aligned}\] <p>From the above equations, you can understand that minimizing the KL divergence between \(\hat{p} _ {data}^{N}(x)\) and \(p_{\theta}(x)\) is equivalent to maximum likelihood estimation. Thus, in common maximum likelihood estimation, we should keep in mind that we use KL divergence as a distance metric. Due to the assymmetry property of KL divergence, there may be undesirable effects on learned results. In addition, we use \(\hat{p}_{data}^{N}(x)\) instead of \(p_{data}(x)\). Therefore, maximum likelihood estimation does not necessarilly lead to generalization. For example, if the number of training samples $N$ is small, you can fall into over-fitting.</p> <h2 id="3-reference">3. Reference</h2> <ul> <li>Summer seminar “Deep Generative Models” provided by <a href="https://weblab.t.u-tokyo.ac.jp/">Matsuo Lab</a></li> </ul>]]></content><author><name></name></author><category term="ML"/><category term="generative-model"/><summary type="html"><![CDATA[motivation and a basic framework of generative models]]></summary></entry><entry><title type="html">Displaying External Posts on Your al-folio Blog</title><link href="https://masahiro-negishi.github.io/blog/2022/displaying-external-posts-on-your-al-folio-blog/" rel="alternate" type="text/html" title="Displaying External Posts on Your al-folio Blog"/><published>2022-04-23T23:20:09+00:00</published><updated>2022-04-23T23:20:09+00:00</updated><id>https://masahiro-negishi.github.io/blog/2022/displaying-external-posts-on-your-al-folio-blog</id><content type="html" xml:base="https://masahiro-negishi.github.io/blog/2022/displaying-external-posts-on-your-al-folio-blog/"><![CDATA[]]></content><author><name></name></author></entry></feed>